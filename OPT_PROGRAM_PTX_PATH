//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

	// .globl	A                       // -- Begin function A
.func  (.param .b64 func_retval0) _Z13get_global_idj
(
	.param .b32 _Z13get_global_idj_param_0
)
;
                                        // @A
.entry A(
	.param .u64 .ptr .global .align 4 A_param_0,
	.param .u64 .ptr .global .align 4 A_param_1,
	.param .u64 .ptr .global .align 4 A_param_2,
	.param .u32 A_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<13>;

// %bb.0:                               // %entry
	ld.param.u64 	%rd4, [A_param_2];
	ld.param.u64 	%rd3, [A_param_0];
	mov.u32 	%r1, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r1;
	.param .b64 retval0;
	call.uni (retval0), 
	_Z13get_global_idj, 
	(
	param0
	);
	ld.param.b64 	%rd5, [retval0+0];
	} // callseq 0
	ld.param.u64 	%rd7, [A_param_1];
	shl.b64 	%rd8, %rd5, 32;
	cvt.s64.s32 	%rd1, %rd5;
	setp.lt.u64 	%p1, %rd1, %rd4;
	shr.s64 	%rd9, %rd8, 30;
	add.s64 	%rd2, %rd7, %rd9;
	@%p1 bra 	LBB0_2;
	bra.uni 	LBB0_1;
LBB0_2:                                 // %if.then
	st.global.u32 	[%rd2], %r1;
	mov.f32 	%f6, 0f00000000;
	bra.uni 	LBB0_3;
LBB0_1:                                 // %entry.if.end_crit_edge
	ld.global.f32 	%f6, [%rd2];
LBB0_3:                                 // %if.end
	shl.b64 	%rd10, %rd1, 2;
	add.s64 	%rd11, %rd3, %rd10;
	ld.global.f32 	%f4, [%rd11];
	add.rn.f32 	%f5, %f6, %f4;
	add.s64 	%rd12, %rd4, %rd10;
	st.global.f32 	[%rd12], %f5;
	ret;
                                        // -- End function
}


//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

	// .globl	A                       // -- Begin function A
.func  (.param .b64 func_retval0) _Z13get_global_idj
(
	.param .b32 _Z13get_global_idj_param_0
)
;
.weak .global .align 8 .b8 _llvm_order_file_buffer[1048576];
.weak .global .align 4 .u32 _llvm_order_file_buffer_idx;
.global .align 1 .b8 bitmap_0[1];
                                        // @A
.entry A(
	.param .u64 .ptr .global .align 4 A_param_0,
	.param .u64 .ptr .global .align 4 A_param_1,
	.param .u64 .ptr .global .align 4 A_param_2,
	.param .u32 A_param_3
)
{
	.reg .pred 	%p<3>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<5>;
	.reg .b64 	%rd<18>;

// %bb.0:                               // %order_file_entry
	ld.param.u64 	%rd5, [A_param_2];
	ld.param.u64 	%rd4, [A_param_1];
	ld.global.u8 	%rs1, [bitmap_0];
	mov.u16 	%rs2, 1;
	st.global.u8 	[bitmap_0], %rs2;
	setp.ne.s16 	%p1, %rs1, 0;
	@%p1 bra 	LBB0_2;
// %bb.1:                               // %order_file_set
	mov.u64 	%rd6, _llvm_order_file_buffer_idx;
	atom.global.add.u32 	%r1, [%rd6], 1;
	and.b32  	%r2, %r1, 131071;
	mul.wide.u32 	%rd7, %r2, 8;
	mov.u64 	%rd8, _llvm_order_file_buffer;
	add.s64 	%rd9, %rd8, %rd7;
	mov.u64 	%rd10, -6336661538222193281;
	st.global.u64 	[%rd9], %rd10;
LBB0_2:                                 // %entry
	ld.param.u64 	%rd3, [A_param_0];
	mov.u32 	%r3, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r3;
	.param .b64 retval0;
	call.uni (retval0), 
	_Z13get_global_idj, 
	(
	param0
	);
	ld.param.b64 	%rd11, [retval0+0];
	} // callseq 0
	shl.b64 	%rd13, %rd11, 32;
	cvt.s64.s32 	%rd1, %rd11;
	setp.lt.u64 	%p2, %rd1, %rd5;
	shr.s64 	%rd14, %rd13, 30;
	add.s64 	%rd2, %rd4, %rd14;
	@%p2 bra 	LBB0_4;
	bra.uni 	LBB0_3;
LBB0_4:                                 // %if.then
	st.global.u32 	[%rd2], %r3;
	mov.f32 	%f6, 0f00000000;
	bra.uni 	LBB0_5;
LBB0_3:                                 // %entry.if.end_crit_edge
	ld.global.f32 	%f6, [%rd2];
LBB0_5:                                 // %if.end
	shl.b64 	%rd15, %rd1, 2;
	add.s64 	%rd16, %rd3, %rd15;
	ld.global.f32 	%f4, [%rd16];
	add.rn.f32 	%f5, %f6, %f4;
	add.s64 	%rd17, %rd5, %rd15;
	st.global.f32 	[%rd17], %f5;
	ret;
                                        // -- End function
}


//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

	// .globl	wibble                  // -- Begin function wibble
.func  (.param .b64 func_retval0) hoge
(
	.param .b32 hoge_param_0
)
;
                                        // @wibble
.entry wibble(
	.param .u64 .ptr .global .align 4 wibble_param_0,
	.param .u64 .ptr .global .align 4 wibble_param_1,
	.param .u64 .ptr .global .align 4 wibble_param_2,
	.param .u32 wibble_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<13>;

// %bb.0:                               // %bb
	ld.param.u64 	%rd4, [wibble_param_2];
	ld.param.u64 	%rd3, [wibble_param_0];
	mov.u32 	%r1, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r1;
	.param .b64 retval0;
	call.uni (retval0), 
	hoge, 
	(
	param0
	);
	ld.param.b64 	%rd5, [retval0+0];
	} // callseq 0
	ld.param.u64 	%rd7, [wibble_param_1];
	shl.b64 	%rd8, %rd5, 32;
	cvt.s64.s32 	%rd1, %rd5;
	setp.lt.u64 	%p1, %rd1, %rd4;
	shr.s64 	%rd9, %rd8, 30;
	add.s64 	%rd2, %rd7, %rd9;
	@%p1 bra 	LBB0_2;
	bra.uni 	LBB0_1;
LBB0_2:                                 // %bb11
	st.global.u32 	[%rd2], %r1;
	mov.f32 	%f6, 0f00000000;
	bra.uni 	LBB0_3;
LBB0_1:                                 // %bb9
	ld.global.f32 	%f6, [%rd2];
LBB0_3:                                 // %bb12
	shl.b64 	%rd10, %rd1, 2;
	add.s64 	%rd11, %rd3, %rd10;
	ld.global.f32 	%f4, [%rd11];
	add.rn.f32 	%f5, %f6, %f4;
	add.s64 	%rd12, %rd4, %rd10;
	st.global.f32 	[%rd12], %f5;
	ret;
                                        // -- End function
}
À

//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

	// .globl	A                       // -- Begin function A
.func  (.param .b64 func_retval0) _Z13get_global_idj
(
	.param .b32 _Z13get_global_idj_param_0
)
;
                                        // @A
.entry A(
	.param .u64 .ptr .global .align 4 A_param_0,
	.param .u64 .ptr .global .align 4 A_param_1,
	.param .u64 .ptr .global .align 4 A_param_2,
	.param .u32 A_param_3
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<10>;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<13>;

// %bb.0:                               // %entry
	ld.param.u64 	%rd4, [A_param_2];
	mov.u32 	%r1, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r1;
	.param .b64 retval0;
	call.uni (retval0), 
	_Z13get_global_idj, 
	(
	param0
	);
	ld.param.b64 	%rd5, [retval0+0];
	} // callseq 0
	ld.param.u64 	%rd7, [A_param_1];
	shl.b64 	%rd8, %rd5, 32;
	cvt.s64.s32 	%rd1, %rd5;
	setp.lt.u64 	%p3, %rd1, %rd4;
	shr.s64 	%rd9, %rd8, 30;
	add.s64 	%rd2, %rd7, %rd9;
	mov.pred 	%p5, -1;
                                        // implicit-def: %f9
	@%p3 bra 	LBB0_2;
// %bb.1:                               // %entry.if.end_crit_edge
	ld.global.f32 	%f9, [%rd2];
	mov.pred 	%p5, 0;
LBB0_2:                                 // %Flow
	ld.param.u64 	%rd3, [A_param_0];
	@!%p5 bra 	LBB0_4;
	bra.uni 	LBB0_3;
LBB0_3:                                 // %if.then
	st.global.u32 	[%rd2], %r1;
	mov.f32 	%f9, 0f00000000;
LBB0_4:                                 // %if.end
	shl.b64 	%rd10, %rd1, 2;
	add.s64 	%rd11, %rd3, %rd10;
	ld.global.f32 	%f6, [%rd11];
	add.rn.f32 	%f7, %f9, %f6;
	add.s64 	%rd12, %rd4, %rd10;
	st.global.f32 	[%rd12], %f7;
	ret;
                                        // -- End function
}


//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

.func  (.param .b64 func_retval0) _Z13get_global_idj
(
	.param .b32 _Z13get_global_idj_param_0
)
;
.global .align 8 .b8 _llvm_order_file_buffer[1048576];
.global .align 4 .u32 _llvm_order_file_buffer_idx;
.global .align 1 .b8 bitmap_0[1];
                                        // -- Begin function A
                                        // @A
.entry A(
	.param .u64 .ptr .global .align 4 A_param_0,
	.param .u64 .ptr .global .align 4 A_param_1,
	.param .u64 .ptr .global .align 4 A_param_2,
	.param .u32 A_param_3
)
{
	.reg .pred 	%p<3>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<5>;
	.reg .b64 	%rd<18>;

// %bb.0:                               // %order_file_entry
	ld.param.u64 	%rd5, [A_param_2];
	ld.param.u64 	%rd4, [A_param_1];
	ld.global.u8 	%rs1, [bitmap_0];
	mov.u16 	%rs2, 1;
	st.global.u8 	[bitmap_0], %rs2;
	setp.ne.s16 	%p1, %rs1, 0;
	@%p1 bra 	LBB0_2;
// %bb.1:                               // %order_file_set
	mov.u64 	%rd6, _llvm_order_file_buffer_idx;
	atom.global.add.u32 	%r1, [%rd6], 1;
	and.b32  	%r2, %r1, 131071;
	mul.wide.u32 	%rd7, %r2, 8;
	mov.u64 	%rd8, _llvm_order_file_buffer;
	add.s64 	%rd9, %rd8, %rd7;
	mov.u64 	%rd10, -6336661538222193281;
	st.global.u64 	[%rd9], %rd10;
LBB0_2:                                 // %entry
	ld.param.u64 	%rd3, [A_param_0];
	mov.u32 	%r3, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r3;
	.param .b64 retval0;
	call.uni (retval0), 
	_Z13get_global_idj, 
	(
	param0
	);
	ld.param.b64 	%rd11, [retval0+0];
	} // callseq 0
	shl.b64 	%rd13, %rd11, 32;
	cvt.s64.s32 	%rd1, %rd11;
	setp.lt.u64 	%p2, %rd1, %rd5;
	shr.s64 	%rd14, %rd13, 30;
	add.s64 	%rd2, %rd4, %rd14;
	@%p2 bra 	LBB0_4;
	bra.uni 	LBB0_3;
LBB0_4:                                 // %if.then
	st.global.u32 	[%rd2], %r3;
	mov.f32 	%f6, 0f00000000;
	bra.uni 	LBB0_5;
LBB0_3:                                 // %entry.if.end_crit_edge
	ld.global.f32 	%f6, [%rd2];
LBB0_5:                                 // %if.end
	shl.b64 	%rd15, %rd1, 2;
	add.s64 	%rd16, %rd3, %rd15;
	ld.global.f32 	%f4, [%rd16];
	add.rn.f32 	%f5, %f6, %f4;
	add.s64 	%rd17, %rd5, %rd15;
	st.global.f32 	[%rd17], %f5;
	ret;
                                        // -- End function
}


//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

	// .globl	A                       // -- Begin function A
.func  (.param .b64 func_retval0) _Z13get_global_idj
(
	.param .b32 _Z13get_global_idj_param_0
)
;
                                        // @A
.entry A(
	.param .u64 .ptr .global .align 4 A_param_0,
	.param .u64 .ptr .global .align 4 A_param_1,
	.param .u64 .ptr .global .align 4 A_param_2,
	.param .u32 A_param_3
)
{
	.reg .pred 	%p<3>;
	.reg .f32 	%f<10>;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<13>;

// %bb.0:                               // %entry
	ld.param.u64 	%rd4, [A_param_2];
	mov.u32 	%r1, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r1;
	.param .b64 retval0;
	call.uni (retval0), 
	_Z13get_global_idj, 
	(
	param0
	);
	ld.param.b64 	%rd5, [retval0+0];
	} // callseq 0
	ld.param.u64 	%rd7, [A_param_1];
	shl.b64 	%rd8, %rd5, 32;
	cvt.s64.s32 	%rd1, %rd5;
	setp.lt.u64 	%p1, %rd1, %rd4;
	shr.s64 	%rd9, %rd8, 30;
	add.s64 	%rd2, %rd7, %rd9;
                                        // implicit-def: %f9
	@%p1 bra 	LBB0_2;
// %bb.1:                               // %entry.if.end_crit_edge
	ld.global.f32 	%f9, [%rd2];
LBB0_2:                                 // %Flow
	ld.param.u64 	%rd3, [A_param_0];
	setp.ge.u64 	%p2, %rd1, %rd4;
	@%p2 bra 	LBB0_4;
// %bb.3:                               // %if.then
	st.global.u32 	[%rd2], %r1;
	mov.f32 	%f9, 0f00000000;
LBB0_4:                                 // %if.end
	shl.b64 	%rd10, %rd1, 2;
	add.s64 	%rd11, %rd3, %rd10;
	ld.global.f32 	%f6, [%rd11];
	add.rn.f32 	%f7, %f9, %f6;
	add.s64 	%rd12, %rd4, %rd10;
	st.global.f32 	[%rd12], %f7;
	ret;
                                        // -- End function
}
8

//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

.func  (.param .b64 func_retval0) _Z13get_global_idj
(
	.param .b32 _Z13get_global_idj_param_0
)
;
                                        // -- Begin function A
                                        // @A
.entry A(
	.param .u64 .ptr .global .align 4 A_param_0,
	.param .u64 .ptr .global .align 4 A_param_1,
	.param .u64 .ptr .global .align 4 A_param_2,
	.param .u32 A_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<13>;

// %bb.0:                               // %entry
	ld.param.u64 	%rd4, [A_param_2];
	ld.param.u64 	%rd3, [A_param_0];
	mov.u32 	%r1, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r1;
	.param .b64 retval0;
	call.uni (retval0), 
	_Z13get_global_idj, 
	(
	param0
	);
	ld.param.b64 	%rd5, [retval0+0];
	} // callseq 0
	ld.param.u64 	%rd7, [A_param_1];
	shl.b64 	%rd8, %rd5, 32;
	cvt.s64.s32 	%rd1, %rd5;
	setp.lt.u64 	%p1, %rd1, %rd4;
	shr.s64 	%rd9, %rd8, 30;
	add.s64 	%rd2, %rd7, %rd9;
	@%p1 bra 	LBB0_2;
	bra.uni 	LBB0_1;
LBB0_2:                                 // %if.then
	st.global.u32 	[%rd2], %r1;
	mov.f32 	%f6, 0f00000000;
	bra.uni 	LBB0_3;
LBB0_1:                                 // %entry.if.end_crit_edge
	ld.global.f32 	%f6, [%rd2];
LBB0_3:                                 // %if.end
	shl.b64 	%rd10, %rd1, 2;
	add.s64 	%rd11, %rd3, %rd10;
	ld.global.f32 	%f4, [%rd11];
	add.rn.f32 	%f5, %f6, %f4;
	add.s64 	%rd12, %rd4, %rd10;
	st.global.f32 	[%rd12], %f5;
	ret;
                                        // -- End function
}


//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

.func  (.param .b64 func_retval0) _Z13get_global_idj
(
	.param .b32 _Z13get_global_idj_param_0
)
;
                                        // -- Begin function A
                                        // @A
.entry A(
	.param .u64 .ptr .global .align 4 A_param_0,
	.param .u64 .ptr .global .align 4 A_param_1,
	.param .u64 .ptr .global .align 4 A_param_2,
	.param .u32 A_param_3
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<10>;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<13>;

// %bb.0:                               // %entry
	ld.param.u64 	%rd4, [A_param_2];
	mov.u32 	%r1, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r1;
	.param .b64 retval0;
	call.uni (retval0), 
	_Z13get_global_idj, 
	(
	param0
	);
	ld.param.b64 	%rd5, [retval0+0];
	} // callseq 0
	ld.param.u64 	%rd7, [A_param_1];
	shl.b64 	%rd8, %rd5, 32;
	cvt.s64.s32 	%rd1, %rd5;
	setp.lt.u64 	%p3, %rd1, %rd4;
	shr.s64 	%rd9, %rd8, 30;
	add.s64 	%rd2, %rd7, %rd9;
	mov.pred 	%p5, -1;
                                        // implicit-def: %f9
	@%p3 bra 	LBB0_2;
// %bb.1:                               // %entry.if.end_crit_edge
	ld.global.f32 	%f9, [%rd2];
	mov.pred 	%p5, 0;
LBB0_2:                                 // %Flow
	ld.param.u64 	%rd3, [A_param_0];
	@!%p5 bra 	LBB0_4;
	bra.uni 	LBB0_3;
LBB0_3:                                 // %if.then
	st.global.u32 	[%rd2], %r1;
	mov.f32 	%f9, 0f00000000;
LBB0_4:                                 // %if.end
	shl.b64 	%rd10, %rd1, 2;
	add.s64 	%rd11, %rd3, %rd10;
	ld.global.f32 	%f6, [%rd11];
	add.rn.f32 	%f7, %f9, %f6;
	add.s64 	%rd12, %rd4, %rd10;
	st.global.f32 	[%rd12], %f7;
	ret;
                                        // -- End function
}
9

//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

	// .globl	wibble                  // -- Begin function wibble
.func  (.param .b64 func_retval0) hoge
(
	.param .b32 hoge_param_0
)
;
.extern .global .align 8 .u64 global;
                                        // @wibble
.entry wibble(
	.param .u64 .ptr .global .align 4 wibble_param_0,
	.param .u64 .ptr .global .align 4 wibble_param_1,
	.param .u64 .ptr .global .align 4 wibble_param_2,
	.param .u32 wibble_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<13>;

// %bb.0:                               // %bb
	ld.param.u64 	%rd4, [wibble_param_2];
	ld.param.u64 	%rd3, [wibble_param_0];
	mov.u32 	%r1, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r1;
	.param .b64 retval0;
	call.uni (retval0), 
	hoge, 
	(
	param0
	);
	ld.param.b64 	%rd5, [retval0+0];
	} // callseq 0
	ld.param.u64 	%rd7, [wibble_param_1];
	shl.b64 	%rd8, %rd5, 32;
	cvt.s64.s32 	%rd1, %rd5;
	setp.lt.u64 	%p1, %rd1, %rd4;
	shr.s64 	%rd9, %rd8, 30;
	add.s64 	%rd2, %rd7, %rd9;
	@%p1 bra 	LBB0_2;
	bra.uni 	LBB0_1;
LBB0_2:                                 // %bb12
	st.global.u32 	[%rd2], %r1;
	mov.f32 	%f6, 0f00000000;
	bra.uni 	LBB0_3;
LBB0_1:                                 // %bb10
	ld.global.f32 	%f6, [%rd2];
LBB0_3:                                 // %bb13
	shl.b64 	%rd10, %rd1, 2;
	add.s64 	%rd11, %rd3, %rd10;
	ld.global.f32 	%f4, [%rd11];
	add.rn.f32 	%f5, %f6, %f4;
	add.s64 	%rd12, %rd4, %rd10;
	st.global.f32 	[%rd12], %f5;
	ret;
                                        // -- End function
}


//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

.func  (.param .b64 func_retval0) _Z13get_global_idj
(
	.param .b32 _Z13get_global_idj_param_0
)
;
.extern .global .align 8 .u64 __memprof_shadow_memory_dynamic_address;
                                        // -- Begin function A
                                        // @A
.entry A(
	.param .u64 .ptr .global .align 4 A_param_0,
	.param .u64 .ptr .global .align 4 A_param_1,
	.param .u64 .ptr .global .align 4 A_param_2,
	.param .u32 A_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<13>;

// %bb.0:                               // %entry
	ld.param.u64 	%rd4, [A_param_2];
	ld.param.u64 	%rd3, [A_param_0];
	mov.u32 	%r1, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r1;
	.param .b64 retval0;
	call.uni (retval0), 
	_Z13get_global_idj, 
	(
	param0
	);
	ld.param.b64 	%rd5, [retval0+0];
	} // callseq 0
	ld.param.u64 	%rd7, [A_param_1];
	shl.b64 	%rd8, %rd5, 32;
	cvt.s64.s32 	%rd1, %rd5;
	setp.lt.u64 	%p1, %rd1, %rd4;
	shr.s64 	%rd9, %rd8, 30;
	add.s64 	%rd2, %rd7, %rd9;
	@%p1 bra 	LBB0_2;
	bra.uni 	LBB0_1;
LBB0_2:                                 // %if.then
	st.global.u32 	[%rd2], %r1;
	mov.f32 	%f6, 0f00000000;
	bra.uni 	LBB0_3;
LBB0_1:                                 // %entry.if.end_crit_edge
	ld.global.f32 	%f6, [%rd2];
LBB0_3:                                 // %if.end
	shl.b64 	%rd10, %rd1, 2;
	add.s64 	%rd11, %rd3, %rd10;
	ld.global.f32 	%f4, [%rd11];
	add.rn.f32 	%f5, %f6, %f4;
	add.s64 	%rd12, %rd4, %rd10;
	st.global.f32 	[%rd12], %f5;
	ret;
                                        // -- End function
}


//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

	// .globl	A                       // -- Begin function A
.func  (.param .b64 func_retval0) _Z13get_global_idj
(
	.param .b32 _Z13get_global_idj_param_0
)
;
.weak .global .align 8 .b8 _llvm_order_file_buffer[1048576];
.weak .global .align 4 .u32 _llvm_order_file_buffer_idx;
.global .align 1 .b8 bitmap_0[1];
.weak .global .align 8 .b8 _llvm_order_file_buffer1[1048576];
.weak .global .align 4 .u32 _llvm_order_file_buffer_idx2;
.global .align 1 .b8 bitmap_03[1];
                                        // @A
.entry A(
	.param .u64 .ptr .global .align 4 A_param_0,
	.param .u64 .ptr .global .align 4 A_param_1,
	.param .u64 .ptr .global .align 4 A_param_2,
	.param .u32 A_param_3
)
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<5>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<23>;

// %bb.0:                               // %order_file_entry1
	ld.global.u8 	%rs1, [bitmap_03];
	mov.u16 	%rs2, 1;
	st.global.u8 	[bitmap_03], %rs2;
	setp.ne.s16 	%p1, %rs1, 0;
	@%p1 bra 	LBB0_2;
// %bb.1:                               // %order_file_set2
	mov.u64 	%rd6, _llvm_order_file_buffer_idx2;
	atom.global.add.u32 	%r1, [%rd6], 1;
	and.b32  	%r2, %r1, 131071;
	mul.wide.u32 	%rd7, %r2, 8;
	mov.u64 	%rd8, _llvm_order_file_buffer1;
	add.s64 	%rd9, %rd8, %rd7;
	mov.u64 	%rd10, -6336661538222193281;
	st.global.u64 	[%rd9], %rd10;
LBB0_2:                                 // %order_file_entry
	ld.param.u64 	%rd5, [A_param_2];
	ld.param.u64 	%rd4, [A_param_1];
	ld.global.u8 	%rs3, [bitmap_0];
	st.global.u8 	[bitmap_0], %rs2;
	setp.ne.s16 	%p2, %rs3, 0;
	@%p2 bra 	LBB0_4;
// %bb.3:                               // %order_file_set
	mov.u64 	%rd11, _llvm_order_file_buffer_idx;
	atom.global.add.u32 	%r3, [%rd11], 1;
	and.b32  	%r4, %r3, 131071;
	mul.wide.u32 	%rd12, %r4, 8;
	mov.u64 	%rd13, _llvm_order_file_buffer;
	add.s64 	%rd14, %rd13, %rd12;
	mov.u64 	%rd15, -6336661538222193281;
	st.global.u64 	[%rd14], %rd15;
LBB0_4:                                 // %entry
	ld.param.u64 	%rd3, [A_param_0];
	mov.u32 	%r5, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r5;
	.param .b64 retval0;
	call.uni (retval0), 
	_Z13get_global_idj, 
	(
	param0
	);
	ld.param.b64 	%rd16, [retval0+0];
	} // callseq 0
	shl.b64 	%rd18, %rd16, 32;
	cvt.s64.s32 	%rd1, %rd16;
	setp.lt.u64 	%p3, %rd1, %rd5;
	shr.s64 	%rd19, %rd18, 30;
	add.s64 	%rd2, %rd4, %rd19;
	@%p3 bra 	LBB0_6;
	bra.uni 	LBB0_5;
LBB0_6:                                 // %if.then
	st.global.u32 	[%rd2], %r5;
	mov.f32 	%f6, 0f00000000;
	bra.uni 	LBB0_7;
LBB0_5:                                 // %entry.if.end_crit_edge
	ld.global.f32 	%f6, [%rd2];
LBB0_7:                                 // %if.end
	shl.b64 	%rd20, %rd1, 2;
	add.s64 	%rd21, %rd3, %rd20;
	ld.global.f32 	%f4, [%rd21];
	add.rn.f32 	%f5, %f6, %f4;
	add.s64 	%rd22, %rd5, %rd20;
	st.global.f32 	[%rd22], %f5;
	ret;
                                        // -- End function
}
A

//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

	// .globl	wibble                  // -- Begin function wibble
.func  (.param .b64 func_retval0) hoge
(
	.param .b32 hoge_param_0
)
;
.weak .global .align 8 .b8 global[1048576];
.weak .global .align 4 .u32 global1;
.global .align 1 .b8 global2[1];
                                        // @wibble
.entry wibble(
	.param .u64 .ptr .global .align 4 wibble_param_0,
	.param .u64 .ptr .global .align 4 wibble_param_1,
	.param .u64 .ptr .global .align 4 wibble_param_2,
	.param .u32 wibble_param_3
)
{
	.reg .pred 	%p<3>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<5>;
	.reg .b64 	%rd<18>;

// %bb.0:                               // %bb
	ld.param.u64 	%rd5, [wibble_param_2];
	ld.param.u64 	%rd4, [wibble_param_1];
	ld.global.u8 	%rs1, [global2];
	mov.u16 	%rs2, 1;
	st.global.u8 	[global2], %rs2;
	setp.ne.s16 	%p1, %rs1, 0;
	@%p1 bra 	LBB0_2;
// %bb.1:                               // %bb5
	mov.u64 	%rd6, global1;
	atom.global.add.u32 	%r1, [%rd6], 1;
	and.b32  	%r2, %r1, 131071;
	mul.wide.u32 	%rd7, %r2, 8;
	mov.u64 	%rd8, global;
	add.s64 	%rd9, %rd8, %rd7;
	mov.u64 	%rd10, -6336661538222193281;
	st.global.u64 	[%rd9], %rd10;
LBB0_2:                                 // %bb9
	ld.param.u64 	%rd3, [wibble_param_0];
	mov.u32 	%r3, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r3;
	.param .b64 retval0;
	call.uni (retval0), 
	hoge, 
	(
	param0
	);
	ld.param.b64 	%rd11, [retval0+0];
	} // callseq 0
	shl.b64 	%rd13, %rd11, 32;
	cvt.s64.s32 	%rd1, %rd11;
	setp.lt.u64 	%p2, %rd1, %rd5;
	shr.s64 	%rd14, %rd13, 30;
	add.s64 	%rd2, %rd4, %rd14;
	@%p2 bra 	LBB0_4;
	bra.uni 	LBB0_3;
LBB0_4:                                 // %bb18
	st.global.u32 	[%rd2], %r3;
	mov.f32 	%f6, 0f00000000;
	bra.uni 	LBB0_5;
LBB0_3:                                 // %bb16
	ld.global.f32 	%f6, [%rd2];
LBB0_5:                                 // %bb19
	shl.b64 	%rd15, %rd1, 2;
	add.s64 	%rd16, %rd3, %rd15;
	ld.global.f32 	%f4, [%rd16];
	add.rn.f32 	%f5, %f6, %f4;
	add.s64 	%rd17, %rd5, %rd15;
	st.global.f32 	[%rd17], %f5;
	ret;
                                        // -- End function
}


//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

	// .globl	A                       // -- Begin function A
.func  (.param .b64 func_retval0) _Z13get_global_idj
(
	.param .b32 _Z13get_global_idj_param_0
)
;
.weak .global .align 8 .b8 _llvm_order_file_buffer[1048576];
.weak .global .align 4 .u32 _llvm_order_file_buffer_idx;
.global .align 1 .b8 bitmap_0[1];
                                        // @A
.entry A(
	.param .u64 .ptr .global .align 4 A_param_0,
	.param .u64 .ptr .global .align 4 A_param_1,
	.param .u64 .ptr .global .align 4 A_param_2,
	.param .u32 A_param_3
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<10>;
	.reg .b32 	%r<5>;
	.reg .b64 	%rd<18>;

// %bb.0:                               // %order_file_entry
	ld.param.u64 	%rd5, [A_param_2];
	ld.param.u64 	%rd4, [A_param_1];
	ld.global.u8 	%rs1, [bitmap_0];
	mov.u16 	%rs2, 1;
	st.global.u8 	[bitmap_0], %rs2;
	setp.ne.s16 	%p2, %rs1, 0;
	@%p2 bra 	LBB0_2;
// %bb.1:                               // %order_file_set
	mov.u64 	%rd6, _llvm_order_file_buffer_idx;
	atom.global.add.u32 	%r1, [%rd6], 1;
	and.b32  	%r2, %r1, 131071;
	mul.wide.u32 	%rd7, %r2, 8;
	mov.u64 	%rd8, _llvm_order_file_buffer;
	add.s64 	%rd9, %rd8, %rd7;
	mov.u64 	%rd10, -6336661538222193281;
	st.global.u64 	[%rd9], %rd10;
LBB0_2:                                 // %entry
	mov.u32 	%r3, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r3;
	.param .b64 retval0;
	call.uni (retval0), 
	_Z13get_global_idj, 
	(
	param0
	);
	ld.param.b64 	%rd11, [retval0+0];
	} // callseq 0
	shl.b64 	%rd13, %rd11, 32;
	cvt.s64.s32 	%rd1, %rd11;
	setp.lt.u64 	%p4, %rd1, %rd5;
	shr.s64 	%rd14, %rd13, 30;
	add.s64 	%rd2, %rd4, %rd14;
	mov.pred 	%p6, -1;
                                        // implicit-def: %f9
	@%p4 bra 	LBB0_4;
// %bb.3:                               // %entry.if.end_crit_edge
	ld.global.f32 	%f9, [%rd2];
	mov.pred 	%p6, 0;
LBB0_4:                                 // %Flow
	ld.param.u64 	%rd3, [A_param_0];
	@!%p6 bra 	LBB0_6;
	bra.uni 	LBB0_5;
LBB0_5:                                 // %if.then
	st.global.u32 	[%rd2], %r3;
	mov.f32 	%f9, 0f00000000;
LBB0_6:                                 // %if.end
	shl.b64 	%rd15, %rd1, 2;
	add.s64 	%rd16, %rd3, %rd15;
	ld.global.f32 	%f6, [%rd16];
	add.rn.f32 	%f7, %f9, %f6;
	add.s64 	%rd17, %rd5, %rd15;
	st.global.f32 	[%rd17], %f7;
	ret;
                                        // -- End function
}


//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

.func  (.param .b64 func_retval0) _Z13get_global_idj
(
	.param .b32 _Z13get_global_idj_param_0
)
;
.global .align 8 .b8 _llvm_order_file_buffer[1048576];
.global .align 4 .u32 _llvm_order_file_buffer_idx;
.global .align 1 .b8 bitmap_0[1];
.global .align 8 .b8 _llvm_order_file_buffer1[1048576];
.global .align 4 .u32 _llvm_order_file_buffer_idx2;
.global .align 1 .b8 bitmap_03[1];
                                        // -- Begin function A
                                        // @A
.entry A(
	.param .u64 .ptr .global .align 4 A_param_0,
	.param .u64 .ptr .global .align 4 A_param_1,
	.param .u64 .ptr .global .align 4 A_param_2,
	.param .u32 A_param_3
)
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<5>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<23>;

// %bb.0:                               // %order_file_entry1
	ld.global.u8 	%rs1, [bitmap_03];
	mov.u16 	%rs2, 1;
	st.global.u8 	[bitmap_03], %rs2;
	setp.ne.s16 	%p1, %rs1, 0;
	@%p1 bra 	LBB0_2;
// %bb.1:                               // %order_file_set2
	mov.u64 	%rd6, _llvm_order_file_buffer_idx2;
	atom.global.add.u32 	%r1, [%rd6], 1;
	and.b32  	%r2, %r1, 131071;
	mul.wide.u32 	%rd7, %r2, 8;
	mov.u64 	%rd8, _llvm_order_file_buffer1;
	add.s64 	%rd9, %rd8, %rd7;
	mov.u64 	%rd10, -6336661538222193281;
	st.global.u64 	[%rd9], %rd10;
LBB0_2:                                 // %order_file_entry
	ld.param.u64 	%rd5, [A_param_2];
	ld.param.u64 	%rd4, [A_param_1];
	ld.global.u8 	%rs3, [bitmap_0];
	st.global.u8 	[bitmap_0], %rs2;
	setp.ne.s16 	%p2, %rs3, 0;
	@%p2 bra 	LBB0_4;
// %bb.3:                               // %order_file_set
	mov.u64 	%rd11, _llvm_order_file_buffer_idx;
	atom.global.add.u32 	%r3, [%rd11], 1;
	and.b32  	%r4, %r3, 131071;
	mul.wide.u32 	%rd12, %r4, 8;
	mov.u64 	%rd13, _llvm_order_file_buffer;
	add.s64 	%rd14, %rd13, %rd12;
	mov.u64 	%rd15, -6336661538222193281;
	st.global.u64 	[%rd14], %rd15;
LBB0_4:                                 // %entry
	ld.param.u64 	%rd3, [A_param_0];
	mov.u32 	%r5, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r5;
	.param .b64 retval0;
	call.uni (retval0), 
	_Z13get_global_idj, 
	(
	param0
	);
	ld.param.b64 	%rd16, [retval0+0];
	} // callseq 0
	shl.b64 	%rd18, %rd16, 32;
	cvt.s64.s32 	%rd1, %rd16;
	setp.lt.u64 	%p3, %rd1, %rd5;
	shr.s64 	%rd19, %rd18, 30;
	add.s64 	%rd2, %rd4, %rd19;
	@%p3 bra 	LBB0_6;
	bra.uni 	LBB0_5;
LBB0_6:                                 // %if.then
	st.global.u32 	[%rd2], %r5;
	mov.f32 	%f6, 0f00000000;
	bra.uni 	LBB0_7;
LBB0_5:                                 // %entry.if.end_crit_edge
	ld.global.f32 	%f6, [%rd2];
LBB0_7:                                 // %if.end
	shl.b64 	%rd20, %rd1, 2;
	add.s64 	%rd21, %rd3, %rd20;
	ld.global.f32 	%f4, [%rd21];
	add.rn.f32 	%f5, %f6, %f4;
	add.s64 	%rd22, %rd5, %rd20;
	st.global.f32 	[%rd22], %f5;
	ret;
                                        // -- End function
}


//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

	// .globl	A                       // -- Begin function A
.func  (.param .b64 func_retval0) _Z13get_global_idj
(
	.param .b32 _Z13get_global_idj_param_0
)
;
.weak .global .align 8 .b8 _llvm_order_file_buffer[1048576];
.weak .global .align 4 .u32 _llvm_order_file_buffer_idx;
.global .align 1 .b8 bitmap_0[1];
                                        // @A
.entry A(
	.param .u64 .ptr .global .align 4 A_param_0,
	.param .u64 .ptr .global .align 4 A_param_1,
	.param .u64 .ptr .global .align 4 A_param_2,
	.param .u32 A_param_3
)
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<10>;
	.reg .b32 	%r<5>;
	.reg .b64 	%rd<18>;

// %bb.0:                               // %order_file_entry
	ld.param.u64 	%rd5, [A_param_2];
	ld.param.u64 	%rd4, [A_param_1];
	ld.global.u8 	%rs1, [bitmap_0];
	mov.u16 	%rs2, 1;
	st.global.u8 	[bitmap_0], %rs2;
	setp.ne.s16 	%p1, %rs1, 0;
	@%p1 bra 	LBB0_2;
// %bb.1:                               // %order_file_set
	mov.u64 	%rd6, _llvm_order_file_buffer_idx;
	atom.global.add.u32 	%r1, [%rd6], 1;
	and.b32  	%r2, %r1, 131071;
	mul.wide.u32 	%rd7, %r2, 8;
	mov.u64 	%rd8, _llvm_order_file_buffer;
	add.s64 	%rd9, %rd8, %rd7;
	mov.u64 	%rd10, -6336661538222193281;
	st.global.u64 	[%rd9], %rd10;
LBB0_2:                                 // %entry
	mov.u32 	%r3, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r3;
	.param .b64 retval0;
	call.uni (retval0), 
	_Z13get_global_idj, 
	(
	param0
	);
	ld.param.b64 	%rd11, [retval0+0];
	} // callseq 0
	shl.b64 	%rd13, %rd11, 32;
	cvt.s64.s32 	%rd1, %rd11;
	setp.lt.u64 	%p2, %rd1, %rd5;
	shr.s64 	%rd14, %rd13, 30;
	add.s64 	%rd2, %rd4, %rd14;
                                        // implicit-def: %f9
	@%p2 bra 	LBB0_4;
// %bb.3:                               // %entry.if.end_crit_edge
	ld.global.f32 	%f9, [%rd2];
LBB0_4:                                 // %Flow
	ld.param.u64 	%rd3, [A_param_0];
	setp.ge.u64 	%p3, %rd1, %rd5;
	@%p3 bra 	LBB0_6;
// %bb.5:                               // %if.then
	st.global.u32 	[%rd2], %r3;
	mov.f32 	%f9, 0f00000000;
LBB0_6:                                 // %if.end
	shl.b64 	%rd15, %rd1, 2;
	add.s64 	%rd16, %rd3, %rd15;
	ld.global.f32 	%f6, [%rd16];
	add.rn.f32 	%f7, %f9, %f6;
	add.s64 	%rd17, %rd5, %rd15;
	st.global.f32 	[%rd17], %f7;
	ret;
                                        // -- End function
}
ÿ

//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

.func  (.param .b64 func_retval0) _Z13get_global_idj
(
	.param .b32 _Z13get_global_idj_param_0
)
;
.global .align 8 .b8 _llvm_order_file_buffer[1048576];
.global .align 4 .u32 _llvm_order_file_buffer_idx;
.global .align 1 .b8 bitmap_0[1];
                                        // -- Begin function A
                                        // @A
.entry A(
	.param .u64 .ptr .global .align 4 A_param_0,
	.param .u64 .ptr .global .align 4 A_param_1,
	.param .u64 .ptr .global .align 4 A_param_2,
	.param .u32 A_param_3
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<10>;
	.reg .b32 	%r<5>;
	.reg .b64 	%rd<18>;

// %bb.0:                               // %order_file_entry
	ld.param.u64 	%rd5, [A_param_2];
	ld.param.u64 	%rd4, [A_param_1];
	ld.global.u8 	%rs1, [bitmap_0];
	mov.u16 	%rs2, 1;
	st.global.u8 	[bitmap_0], %rs2;
	setp.ne.s16 	%p2, %rs1, 0;
	@%p2 bra 	LBB0_2;
// %bb.1:                               // %order_file_set
	mov.u64 	%rd6, _llvm_order_file_buffer_idx;
	atom.global.add.u32 	%r1, [%rd6], 1;
	and.b32  	%r2, %r1, 131071;
	mul.wide.u32 	%rd7, %r2, 8;
	mov.u64 	%rd8, _llvm_order_file_buffer;
	add.s64 	%rd9, %rd8, %rd7;
	mov.u64 	%rd10, -6336661538222193281;
	st.global.u64 	[%rd9], %rd10;
LBB0_2:                                 // %entry
	mov.u32 	%r3, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r3;
	.param .b64 retval0;
	call.uni (retval0), 
	_Z13get_global_idj, 
	(
	param0
	);
	ld.param.b64 	%rd11, [retval0+0];
	} // callseq 0
	shl.b64 	%rd13, %rd11, 32;
	cvt.s64.s32 	%rd1, %rd11;
	setp.lt.u64 	%p4, %rd1, %rd5;
	shr.s64 	%rd14, %rd13, 30;
	add.s64 	%rd2, %rd4, %rd14;
	mov.pred 	%p6, -1;
                                        // implicit-def: %f9
	@%p4 bra 	LBB0_4;
// %bb.3:                               // %entry.if.end_crit_edge
	ld.global.f32 	%f9, [%rd2];
	mov.pred 	%p6, 0;
LBB0_4:                                 // %Flow
	ld.param.u64 	%rd3, [A_param_0];
	@!%p6 bra 	LBB0_6;
	bra.uni 	LBB0_5;
LBB0_5:                                 // %if.then
	st.global.u32 	[%rd2], %r3;
	mov.f32 	%f9, 0f00000000;
LBB0_6:                                 // %if.end
	shl.b64 	%rd15, %rd1, 2;
	add.s64 	%rd16, %rd3, %rd15;
	ld.global.f32 	%f6, [%rd16];
	add.rn.f32 	%f7, %f9, %f6;
	add.s64 	%rd17, %rd5, %rd15;
	st.global.f32 	[%rd17], %f7;
	ret;
                                        // -- End function
}


//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

	// .globl	wibble                  // -- Begin function wibble
.func  (.param .b64 func_retval0) hoge
(
	.param .b32 hoge_param_0
)
;
.weak .global .align 8 .b8 global[1048576];
.weak .global .align 4 .u32 global1;
.global .align 1 .b8 global2[1];
.extern .global .align 8 .u64 global3;
                                        // @wibble
.entry wibble(
	.param .u64 .ptr .global .align 4 wibble_param_0,
	.param .u64 .ptr .global .align 4 wibble_param_1,
	.param .u64 .ptr .global .align 4 wibble_param_2,
	.param .u32 wibble_param_3
)
{
	.reg .pred 	%p<3>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<5>;
	.reg .b64 	%rd<39>;

// %bb.0:                               // %bb
	ld.param.u64 	%rd6, [wibble_param_2];
	ld.param.u64 	%rd5, [wibble_param_1];
	ld.global.u64 	%rd1, [global3];
	mov.u64 	%rd7, global2;
	cvta.global.u64 	%rd8, %rd7;
	and.b64  	%rd9, %rd8, -64;
	shr.u64 	%rd10, %rd9, 3;
	add.s64 	%rd11, %rd10, %rd1;
	ld.u64 	%rd12, [%rd11];
	add.s64 	%rd13, %rd12, 1;
	st.u64 	[%rd11], %rd13;
	ld.global.u8 	%rs1, [global2];
	add.s64 	%rd14, %rd12, 2;
	st.u64 	[%rd11], %rd14;
	mov.u16 	%rs2, 1;
	st.global.u8 	[global2], %rs2;
	setp.ne.s16 	%p1, %rs1, 0;
	@%p1 bra 	LBB0_2;
// %bb.1:                               // %bb14
	mov.u64 	%rd15, global1;
	cvta.global.u64 	%rd16, %rd15;
	and.b64  	%rd17, %rd16, -64;
	shr.u64 	%rd18, %rd17, 3;
	add.s64 	%rd19, %rd18, %rd1;
	ld.u64 	%rd20, [%rd19];
	add.s64 	%rd21, %rd20, 1;
	st.u64 	[%rd19], %rd21;
	atom.global.add.u32 	%r1, [%rd15], 1;
	and.b32  	%r2, %r1, 131071;
	mul.wide.u32 	%rd22, %r2, 8;
	mov.u64 	%rd23, global;
	add.s64 	%rd24, %rd23, %rd22;
	cvta.global.u64 	%rd25, %rd24;
	and.b64  	%rd26, %rd25, -64;
	shr.u64 	%rd27, %rd26, 3;
	add.s64 	%rd28, %rd27, %rd1;
	ld.u64 	%rd29, [%rd28];
	add.s64 	%rd30, %rd29, 1;
	st.u64 	[%rd28], %rd30;
	mov.u64 	%rd31, -6336661538222193281;
	st.global.u64 	[%rd24], %rd31;
LBB0_2:                                 // %bb29
	ld.param.u64 	%rd4, [wibble_param_0];
	mov.u32 	%r3, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r3;
	.param .b64 retval0;
	call.uni (retval0), 
	hoge, 
	(
	param0
	);
	ld.param.b64 	%rd32, [retval0+0];
	} // callseq 0
	shl.b64 	%rd34, %rd32, 32;
	cvt.s64.s32 	%rd2, %rd32;
	setp.lt.u64 	%p2, %rd2, %rd6;
	shr.s64 	%rd35, %rd34, 30;
	add.s64 	%rd3, %rd5, %rd35;
	@%p2 bra 	LBB0_4;
	bra.uni 	LBB0_3;
LBB0_4:                                 // %bb38
	st.global.u32 	[%rd3], %r3;
	mov.f32 	%f6, 0f00000000;
	bra.uni 	LBB0_5;
LBB0_3:                                 // %bb36
	ld.global.f32 	%f6, [%rd3];
LBB0_5:                                 // %bb39
	shl.b64 	%rd36, %rd2, 2;
	add.s64 	%rd37, %rd4, %rd36;
	ld.global.f32 	%f4, [%rd37];
	add.rn.f32 	%f5, %f6, %f4;
	add.s64 	%rd38, %rd6, %rd36;
	st.global.f32 	[%rd38], %f5;
	ret;
                                        // -- End function
}


//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

.func  (.param .b64 func_retval0) _Z13get_global_idj
(
	.param .b32 _Z13get_global_idj_param_0
)
;
.global .align 8 .b8 _llvm_order_file_buffer[1048576];
.global .align 4 .u32 _llvm_order_file_buffer_idx;
.global .align 1 .b8 bitmap_0[1];
.extern .global .align 8 .u64 __memprof_shadow_memory_dynamic_address;
                                        // -- Begin function A
                                        // @A
.entry A(
	.param .u64 .ptr .global .align 4 A_param_0,
	.param .u64 .ptr .global .align 4 A_param_1,
	.param .u64 .ptr .global .align 4 A_param_2,
	.param .u32 A_param_3
)
{
	.reg .pred 	%p<3>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<5>;
	.reg .b64 	%rd<39>;

// %bb.0:                               // %order_file_entry
	ld.param.u64 	%rd6, [A_param_2];
	ld.param.u64 	%rd5, [A_param_1];
	ld.global.u64 	%rd1, [__memprof_shadow_memory_dynamic_address];
	mov.u64 	%rd7, bitmap_0;
	cvta.global.u64 	%rd8, %rd7;
	and.b64  	%rd9, %rd8, -64;
	shr.u64 	%rd10, %rd9, 3;
	add.s64 	%rd11, %rd10, %rd1;
	ld.u64 	%rd12, [%rd11];
	add.s64 	%rd13, %rd12, 1;
	st.u64 	[%rd11], %rd13;
	ld.global.u8 	%rs1, [bitmap_0];
	add.s64 	%rd14, %rd12, 2;
	st.u64 	[%rd11], %rd14;
	mov.u16 	%rs2, 1;
	st.global.u8 	[bitmap_0], %rs2;
	setp.ne.s16 	%p1, %rs1, 0;
	@%p1 bra 	LBB0_2;
// %bb.1:                               // %order_file_set
	mov.u64 	%rd15, _llvm_order_file_buffer_idx;
	cvta.global.u64 	%rd16, %rd15;
	and.b64  	%rd17, %rd16, -64;
	shr.u64 	%rd18, %rd17, 3;
	add.s64 	%rd19, %rd18, %rd1;
	ld.u64 	%rd20, [%rd19];
	add.s64 	%rd21, %rd20, 1;
	st.u64 	[%rd19], %rd21;
	atom.global.add.u32 	%r1, [%rd15], 1;
	and.b32  	%r2, %r1, 131071;
	mul.wide.u32 	%rd22, %r2, 8;
	mov.u64 	%rd23, _llvm_order_file_buffer;
	add.s64 	%rd24, %rd23, %rd22;
	cvta.global.u64 	%rd25, %rd24;
	and.b64  	%rd26, %rd25, -64;
	shr.u64 	%rd27, %rd26, 3;
	add.s64 	%rd28, %rd27, %rd1;
	ld.u64 	%rd29, [%rd28];
	add.s64 	%rd30, %rd29, 1;
	st.u64 	[%rd28], %rd30;
	mov.u64 	%rd31, -6336661538222193281;
	st.global.u64 	[%rd24], %rd31;
LBB0_2:                                 // %entry
	ld.param.u64 	%rd4, [A_param_0];
	mov.u32 	%r3, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r3;
	.param .b64 retval0;
	call.uni (retval0), 
	_Z13get_global_idj, 
	(
	param0
	);
	ld.param.b64 	%rd32, [retval0+0];
	} // callseq 0
	shl.b64 	%rd34, %rd32, 32;
	cvt.s64.s32 	%rd2, %rd32;
	setp.lt.u64 	%p2, %rd2, %rd6;
	shr.s64 	%rd35, %rd34, 30;
	add.s64 	%rd3, %rd5, %rd35;
	@%p2 bra 	LBB0_4;
	bra.uni 	LBB0_3;
LBB0_4:                                 // %if.then
	st.global.u32 	[%rd3], %r3;
	mov.f32 	%f6, 0f00000000;
	bra.uni 	LBB0_5;
LBB0_3:                                 // %entry.if.end_crit_edge
	ld.global.f32 	%f6, [%rd3];
LBB0_5:                                 // %if.end
	shl.b64 	%rd36, %rd2, 2;
	add.s64 	%rd37, %rd4, %rd36;
	ld.global.f32 	%f4, [%rd37];
	add.rn.f32 	%f5, %f6, %f4;
	add.s64 	%rd38, %rd6, %rd36;
	st.global.f32 	[%rd38], %f5;
	ret;
                                        // -- End function
}


//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

	// .globl	wibble                  // -- Begin function wibble
.func  (.param .b64 func_retval0) hoge
(
	.param .b32 hoge_param_0
)
;
.weak .global .align 8 .b8 _llvm_order_file_buffer[1048576];
.weak .global .align 4 .u32 _llvm_order_file_buffer_idx;
.global .align 1 .b8 bitmap_0[1];
                                        // @wibble
.entry wibble(
	.param .u64 .ptr .global .align 4 wibble_param_0,
	.param .u64 .ptr .global .align 4 wibble_param_1,
	.param .u64 .ptr .global .align 4 wibble_param_2,
	.param .u32 wibble_param_3
)
{
	.reg .pred 	%p<3>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<5>;
	.reg .b64 	%rd<18>;

// %bb.0:                               // %order_file_entry
	ld.param.u64 	%rd5, [wibble_param_2];
	ld.param.u64 	%rd4, [wibble_param_1];
	ld.global.u8 	%rs1, [bitmap_0];
	mov.u16 	%rs2, 1;
	st.global.u8 	[bitmap_0], %rs2;
	setp.ne.s16 	%p1, %rs1, 0;
	@%p1 bra 	LBB0_2;
// %bb.1:                               // %order_file_set
	mov.u64 	%rd6, _llvm_order_file_buffer_idx;
	atom.global.add.u32 	%r1, [%rd6], 1;
	and.b32  	%r2, %r1, 131071;
	mul.wide.u32 	%rd7, %r2, 8;
	mov.u64 	%rd8, _llvm_order_file_buffer;
	add.s64 	%rd9, %rd8, %rd7;
	mov.u64 	%rd10, 9020724533816781904;
	st.global.u64 	[%rd9], %rd10;
LBB0_2:                                 // %bb
	ld.param.u64 	%rd3, [wibble_param_0];
	mov.u32 	%r3, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r3;
	.param .b64 retval0;
	call.uni (retval0), 
	hoge, 
	(
	param0
	);
	ld.param.b64 	%rd11, [retval0+0];
	} // callseq 0
	shl.b64 	%rd13, %rd11, 32;
	cvt.s64.s32 	%rd1, %rd11;
	setp.lt.u64 	%p2, %rd1, %rd5;
	shr.s64 	%rd14, %rd13, 30;
	add.s64 	%rd2, %rd4, %rd14;
	@%p2 bra 	LBB0_4;
	bra.uni 	LBB0_3;
LBB0_4:                                 // %bb11
	st.global.u32 	[%rd2], %r3;
	mov.f32 	%f6, 0f00000000;
	bra.uni 	LBB0_5;
LBB0_3:                                 // %bb9
	ld.global.f32 	%f6, [%rd2];
LBB0_5:                                 // %bb12
	shl.b64 	%rd15, %rd1, 2;
	add.s64 	%rd16, %rd3, %rd15;
	ld.global.f32 	%f4, [%rd16];
	add.rn.f32 	%f5, %f6, %f4;
	add.s64 	%rd17, %rd5, %rd15;
	st.global.f32 	[%rd17], %f5;
	ret;
                                        // -- End function
}
Þ

//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

	// .globl	wibble                  // -- Begin function wibble
.func  (.param .b64 func_retval0) hoge
(
	.param .b32 hoge_param_0
)
;
                                        // @wibble
.entry wibble(
	.param .u64 .ptr .global .align 4 wibble_param_0,
	.param .u64 .ptr .global .align 4 wibble_param_1,
	.param .u64 .ptr .global .align 4 wibble_param_2,
	.param .u32 wibble_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<13>;

// %bb.0:                               // %bb
	ld.param.u64 	%rd4, [wibble_param_2];
	ld.param.u64 	%rd3, [wibble_param_0];
	mov.u32 	%r1, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r1;
	.param .b64 retval0;
	call.uni (retval0), 
	hoge, 
	(
	param0
	);
	ld.param.b64 	%rd5, [retval0+0];
	} // callseq 0
	ld.param.u64 	%rd7, [wibble_param_1];
	shl.b64 	%rd8, %rd5, 32;
	cvt.s64.s32 	%rd1, %rd5;
	setp.lt.u64 	%p1, %rd1, %rd4;
	shr.s64 	%rd9, %rd8, 30;
	add.s64 	%rd2, %rd7, %rd9;
	@%p1 bra 	LBB0_2;
	bra.uni 	LBB0_1;
LBB0_2:                                 // %bb28
	st.global.u32 	[%rd2], %r1;
	mov.f32 	%f6, 0f00000000;
	bra.uni 	LBB0_3;
LBB0_1:                                 // %bb26
	ld.global.f32 	%f6, [%rd2];
LBB0_3:                                 // %bb29
	shl.b64 	%rd10, %rd1, 2;
	add.s64 	%rd11, %rd3, %rd10;
	ld.global.f32 	%f4, [%rd11];
	add.rn.f32 	%f5, %f6, %f4;
	add.s64 	%rd12, %rd4, %rd10;
	st.global.f32 	[%rd12], %f5;
	ret;
                                        // -- End function
}


//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64

	// .globl	wibble                  // -- Begin function wibble
.func  (.param .b64 func_retval0) hoge
(
	.param .b32 hoge_param_0
)
;
                                        // @wibble
.entry wibble(
	.param .u64 .ptr .global .align 4 wibble_param_0,
	.param .u64 .ptr .global .align 4 wibble_param_1,
	.param .u64 .ptr .global .align 4 wibble_param_2,
	.param .u32 wibble_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<13>;

// %bb.0:                               // %bb
	ld.param.u64 	%rd4, [wibble_param_2];
	ld.param.u64 	%rd3, [wibble_param_0];
	mov.u32 	%r1, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r1;
	.param .b64 retval0;
	call.uni (retval0), 
	hoge, 
	(
	param0
	);
	ld.param.b64 	%rd5, [retval0+0];
	} // callseq 0
	ld.param.u64 	%rd7, [wibble_param_1];
	shl.b64 	%rd8, %rd5, 32;
	cvt.s64.s32 	%rd1, %rd5;
	setp.lt.u64 	%p1, %rd1, %rd4;
	shr.s64 	%rd9, %rd8, 30;
	add.s64 	%rd2, %rd7, %rd9;
	@%p1 bra 	LBB0_2;
	bra.uni 	LBB0_1;
LBB0_2:                                 // %bb28
	st.global.u32 	[%rd2], %r1;
	mov.f32 	%f6, 0f00000000;
	bra.uni 	LBB0_3;
LBB0_1:                                 // %bb26
	ld.global.f32 	%f6, [%rd2];
LBB0_3:                                 // %bb29
	shl.b64 	%rd10, %rd1, 2;
	add.s64 	%rd11, %rd3, %rd10;
	ld.global.f32 	%f4, [%rd11];
	add.rn.f32 	%f5, %f6, %f4;
	add.s64 	%rd12, %rd4, %rd10;
	st.global.f32 	[%rd12], %f5;
	ret;
                                        // -- End function
}


//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64




//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60, texmode_independent
.address_size 64




1

